# AWS Cost Analyzer

![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![CI](https://img.shields.io/badge/CI-GitHub%20Actions-blue.svg)

A production-quality Python CLI tool that scans your AWS account for cost leaks and generates actionable recommendations to reduce your monthly bill.

## üéØ What It Does

AWS Cost Analyzer identifies four major categories of cost waste:

1. **Stopped EC2 Instances** - Instances that aren't running but still charge for attached EBS volumes
2. **Unattached EBS Volumes** - Storage volumes not connected to any instance (100% waste)
3. **Old Snapshots** - EBS snapshots older than 90 days that accumulate storage costs
4. **Unassociated Elastic IPs** - Reserved IP addresses not attached to instances ($3.60/month each)

## üí∞ Potential Savings

In a typical AWS account, this tool can identify:
- **10-30% reduction** in EBS storage costs
- **$50-500/month** in forgotten resources
- **Hundreds to thousands annually** for production accounts

## üöÄ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/aws-cost-analyzer.git
cd aws-cost-analyzer

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On macOS/Linux

# Install dependencies
pip install -r requirements.txt
```

### Configure AWS Credentials

```bash
aws configure
# Enter your AWS Access Key ID
# Enter your AWS Secret Access Key
# Default region: eu-west-1
```

### Run a Scan

```bash
# Scan default region
python3 cli.py scan

# Scan specific region
python3 cli.py scan --region us-east-1

# Export results to JSON
python3 cli.py scan --json-output results.json
```

## üê≥ Docker Usage

### Build locally
```bash
cd aws-cost-analyzer
docker build -t aws-cost-analyzer:latest .
```

### Run with AWS credentials
```bash
# Set AWS credentials as environment variables first
export AWS_ACCESS_KEY_ID=your_access_key
export AWS_SECRET_ACCESS_KEY=your_secret_key

# Run scan in container
docker run --rm \
  -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
  -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
  -e AWS_DEFAULT_REGION=eu-west-1 \
  aws-cost-analyzer:latest scan --region eu-west-1
```

### Export results to host
```bash
docker run --rm \
  -v $(pwd):/output \
  -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
  -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
  -e AWS_DEFAULT_REGION=eu-west-1 \
  aws-cost-analyzer:latest scan --json-output /output/report.json
```

**Note:** Always set `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` as environment variables in your shell before running Docker commands. The `$VAR` syntax passes the value from your shell to the container.

## üìä Example Output

```
üîç Scanning AWS account in region: eu-west-1

üìä Scanning EC2 instances...
   Found 3 stopped instances ($24.00/month)

üìä Scanning EBS volumes...
   Found 5 unattached volumes ($50.00/month)

üìä Scanning EBS snapshots...
   Found 8 old snapshots (>90 days) ($40.00/month)

üìä Scanning Elastic IPs...
   Found 2 unassociated EIPs ($7.20/month)

============================================================
| Resource Type              | Count | Monthly Cost |
============================================================
| Stopped EC2 Instances      |     3 | $24.00       |
| Unattached EBS Volumes     |     5 | $50.00       |
| Old Snapshots (>90 days)   |     8 | $40.00       |
| Unassociated Elastic IPs   |     2 | $7.20        |
|                            |       |              |
| TOTAL                      |       | $121.20      |
============================================================

üí∞ Total potential monthly savings: $121.20
üí∞ Annual savings potential: $1,454.40
```

## üèóÔ∏è Architecture

### System Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   User CLI  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         cli.py (Click)              ‚îÇ
‚îÇ  - Parse arguments                  ‚îÇ
‚îÇ  - Orchestrate scanners             ‚îÇ
‚îÇ  - Format output                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Scanner Layer (Cached)         ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ      BaseScanner              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Common initialization      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Caching (5-min TTL)        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Retry logic (transient)    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Error handling            ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ (inherits from)    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ EC2Scanner          ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ EBSScanner          ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ SnapshotScanner     ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ EIPScanner          ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ IAMScanner          ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ S3Scanner           ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      AWS APIs (boto3)               ‚îÇ
‚îÇ  - describe_instances()             ‚îÇ
‚îÇ  - describe_volumes()               ‚îÇ
‚îÇ  - describe_snapshots()             ‚îÇ
‚îÇ  - describe_addresses()             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow

1. User runs CLI command
2. CLI instantiates scanners
3. Scanners check cache (5-minute TTL)
4. If cache miss, query AWS APIs (with retry logic for transient errors)
5. Process and aggregate results
6. Format output (console/JSON/CSV)

### Project Structure

```
aws-cost-analyzer/
‚îú‚îÄ‚îÄ cli.py                   # Main CLI entry point
‚îú‚îÄ‚îÄ scanners/                # Resource scanners
‚îÇ   ‚îú‚îÄ‚îÄ base_scanner.py      # Base class with caching & retry logic
‚îÇ   ‚îú‚îÄ‚îÄ ec2_scanner.py       # Stopped EC2 instances
‚îÇ   ‚îú‚îÄ‚îÄ ebs_scanner.py       # Unattached EBS volumes
‚îÇ   ‚îú‚îÄ‚îÄ snapshot_scanner.py  # Old EBS snapshots
‚îÇ   ‚îú‚îÄ‚îÄ eip_scanner.py       # Unassociated Elastic IPs
‚îÇ   ‚îú‚îÄ‚îÄ iam_scanner.py       # Unused IAM access keys
‚îÇ   ‚îú‚îÄ‚îÄ s3_scanner.py        # Unused S3 buckets
‚îÇ   ‚îî‚îÄ‚îÄ multi_region_scanner.py  # Multi-region scanning
‚îú‚îÄ‚îÄ analyzers/               # Cost analysis logic
‚îÇ   ‚îú‚îÄ‚îÄ cost_analyzer.py     # Main analysis orchestrator
‚îÇ   ‚îú‚îÄ‚îÄ cost_calculator.py   # Cost calculation utilities
‚îÇ   ‚îî‚îÄ‚îÄ cost_explorer.py     # AWS Cost Explorer integration
‚îú‚îÄ‚îÄ models/                  # Data models
‚îÇ   ‚îî‚îÄ‚îÄ leak.py              # Cost leak data structures
‚îú‚îÄ‚îÄ reporters/               # Output formatters
‚îÇ   ‚îú‚îÄ‚îÄ json_reporter.py     # JSON export functionality
‚îÇ   ‚îî‚îÄ‚îÄ csv_reporter.py      # CSV export functionality
‚îú‚îÄ‚îÄ docs/                    # Documentation
‚îÇ   ‚îî‚îÄ‚îÄ architecture.md      # Detailed architecture docs
‚îî‚îÄ‚îÄ tests/                   # Unit tests
    ‚îú‚îÄ‚îÄ test_base_scanner_cache.py
    ‚îú‚îÄ‚îÄ test_ec2_scanner.py
    ‚îú‚îÄ‚îÄ test_ebs_scanner.py
    ‚îú‚îÄ‚îÄ test_snapshot_scanner.py
    ‚îú‚îÄ‚îÄ test_eip_scanner.py
    ‚îú‚îÄ‚îÄ test_iam_scanner.py
    ‚îú‚îÄ‚îÄ test_s3_scanner.py
    ‚îî‚îÄ‚îÄ test_integration.py
```

## ‚ö° Performance Benchmarks

### Caching Performance

The scanner implements a 5-minute TTL cache to reduce AWS API calls:

- **First scan:** ~5-10 seconds (depends on account size)
- **Cached scan:** ~0.1 seconds (100x faster)
- **Cache hit rate:** ~85% for repeated scans within 5 minutes

### Scan Times (Typical Account)

| Resource Type | First Scan | Cached Scan |
|--------------|------------|-------------|
| EC2 Instances | 2-3s | 0.05s |
| EBS Volumes | 1-2s | 0.03s |
| Snapshots | 3-5s | 0.08s |
| Elastic IPs | 0.5s | 0.02s |
| IAM Keys | 2-4s | N/A (global) |
| S3 Buckets | 1-2s | N/A (global) |
| **Total (6 scanners)** | **10-16s** | **~0.2s** |

### Multi-Region Performance

- **Sequential:** ~30-60 seconds per region √ó N regions
- **Parallel (5 workers):** ~10-15 seconds total for all regions
- **Recommended:** Use `--max-workers 5` for optimal throughput

### Retry Logic Performance

- **Transient errors:** Automatically retried with exponential backoff
- **Retry attempts:** 3 by default (configurable)
- **Backoff:** 1s, 2s, 4s intervals
- **Success rate:** 99%+ for transient AWS throttling errors

## üß™ Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=. --cov-report=html

# Lint code
ruff check .

# Type checking
mypy scanners/ analyzers/ --ignore-missing-imports
```

## üîß Troubleshooting

### "Access Denied" Errors

**Problem:** Getting `AccessDenied` errors when scanning.

**Solutions:**
1. Check IAM permissions - you need read access to EC2, S3, and IAM:
   ```json
   {
     "Version": "2012-10-17",
     "Statement": [
       {
         "Effect": "Allow",
         "Action": [
           "ec2:DescribeInstances",
           "ec2:DescribeVolumes",
           "ec2:DescribeSnapshots",
           "ec2:DescribeAddresses",
           "s3:ListBuckets",
           "s3:ListObjects",
           "iam:ListUsers",
           "iam:ListAccessKeys",
           "iam:GetAccessKeyLastUsed"
         ],
         "Resource": "*"
       }
     ]
   }
   ```
2. Verify AWS credentials: `aws sts get-caller-identity`
3. Check if your AWS profile is set: `aws configure list`

### Cost Explorer Returns Empty

**Problem:** `--show-actual-costs` flag returns $0.00 or empty data.

**Solutions:**
- Cost Explorer takes **24 hours** to populate data after account creation
- Must use **us-east-1** region for Cost Explorer API (automatically handled)
- Ensure Cost Explorer is enabled in your AWS account
- Check billing permissions: `ce:GetCostAndUsage`

### Multi-Region Scan Fails for Some Regions

**Problem:** Some regions fail during `scan-all-regions` command.

**Solutions:**
- Some regions may not be enabled in your account
- Check enabled regions: `aws ec2 describe-regions`
- Enable regions in AWS Console if needed
- Temporary failures are handled gracefully (skipped with error message)

### Throttling Errors (429)

**Problem:** Getting throttled by AWS APIs during scans.

**Solutions:**
- The tool automatically retries with exponential backoff (3 attempts)
- Reduce `--max-workers` if scanning multiple regions: `--max-workers 3`
- Wait 5 minutes and run again (cache will help on second run)
- Consider scanning regions sequentially if throttling persists

### Cache Not Working

**Problem:** Scans taking full time even on repeated runs.

**Solutions:**
- Cache TTL is 5 minutes - wait at least 5 minutes between scans for cache benefit
- Cache is per-scanner instance - ensure you're using the same scanner object
- Check if cache is being cleared: `scanner._clear_cache()` (debug only)
- Multi-region scans don't share cache across regions (by design)

### Python Version Errors

**Problem:** `SyntaxError` or `TypeError` on older Python versions.

**Solutions:**
- Requires Python **3.11+** for type hints and modern features
- Check version: `python3 --version`
- Upgrade Python: `brew install python@3.11` (macOS) or use pyenv

### Docker: "Unable to locate credentials" Error

**Problem:** Getting `NoCredentialsError` when running Docker container.

**Solutions:**
1. **Set environment variables in your shell BEFORE running Docker:**
   ```bash
   export AWS_ACCESS_KEY_ID=your_access_key_here
   export AWS_SECRET_ACCESS_KEY=your_secret_key_here
   export AWS_DEFAULT_REGION=eu-west-1
   ```

2. **Verify variables are set:**
   ```bash
   echo $AWS_ACCESS_KEY_ID  # Should show your key (not empty)
   echo $AWS_SECRET_ACCESS_KEY  # Should show your secret (not empty)
   ```

3. **Alternative: Pass credentials directly (less secure):**
   ```bash
   docker run --rm \
     -e AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE \
     -e AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY \
     -e AWS_DEFAULT_REGION=eu-west-1 \
     aws-cost-analyzer:latest scan --region eu-west-1
   ```

4. **Use AWS credentials file (if you have `~/.aws/credentials`):**
   ```bash
   # Mount AWS credentials directory
   docker run --rm \
     -v ~/.aws:/root/.aws:ro \
     -e AWS_PROFILE=default \
     aws-cost-analyzer:latest scan --region eu-west-1
   ```

**Common mistake:** Running `docker run -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID` when `$AWS_ACCESS_KEY_ID` is empty in your shell. Always `export` the variables first.

## ‚ùì FAQ

### Why does scanning take so long?

First scans query AWS APIs which can take 10-16 seconds depending on account size. Subsequent scans within 5 minutes use cache and complete in ~0.2 seconds.

### How accurate are the cost estimates?

Costs are estimated based on AWS public pricing (as of 2024):
- **EBS volumes:** $0.08-0.125/GB-month (varies by type)
- **Snapshots:** $0.05/GB-month
- **Elastic IPs:** $3.60/month (fixed)
- Actual costs may vary by region and volume type. Use `--show-actual-costs` for real data.

### Can I run this in CI/CD?

Yes! The tool is designed to be non-destructive (read-only):
- No AWS resources are modified
- Safe to run in automated pipelines
- Returns exit code 0 on success, non-zero on errors

### Does this work with AWS Organizations?

Partially. The tool scans resources in the current AWS account/profile. For Organization-wide scanning, run it with appropriate cross-account IAM roles.

### How do I contribute a new scanner?

See [Contributing Guidelines](#-contributing) below. The pattern is straightforward:
1. Inherit from `BaseScanner`
2. Implement `scan_*` method
3. Add unit tests
4. Integrate in `cli.py`

### Is my AWS data sent anywhere?

No. This tool runs **locally** and only queries your AWS account via boto3. No data leaves your machine. All processing happens client-side.

## üìã Requirements

- Python 3.11+
- AWS account with configured credentials
- IAM permissions:
  - `ec2:DescribeInstances`
  - `ec2:DescribeVolumes`
  - `ec2:DescribeSnapshots`
  - `ec2:DescribeAddresses`
  - `s3:ListBuckets`
  - `s3:ListObjects`
  - `iam:ListUsers`
  - `iam:ListAccessKeys`
  - `iam:GetAccessKeyLastUsed`
  - `ce:GetCostAndUsage` (optional, for actual costs)

## üõ†Ô∏è Development

### Running in Development

```bash
# Activate virtual environment
source venv/bin/activate

# Install development dependencies
pip install -r requirements.txt

# Run linter
ruff check . --fix

# Run tests with verbose output
pytest tests/ -v -s
```

### Adding a New Scanner

Follow this pattern to add a new resource scanner:

1. **Create scanner file** in `scanners/` directory (e.g., `rds_scanner.py`)

2. **Inherit from BaseScanner:**
   ```python
   from .base_scanner import BaseScanner
   
   class RDSScanner(BaseScanner):
       def __init__(self, region: str = 'eu-west-1'):
           super().__init__(region)
           self.rds_client = boto3.client('rds', region_name=region)
   ```

3. **Implement scan method with caching:**
   ```python
   def scan_unused_db_instances(self, use_cache: bool = True) -> List[Dict[str, Any]]:
       cache_key = self._build_cache_key('unused_db_instances')
       
       if use_cache:
           cached = self._get_cached(cache_key)
           if cached is not None:
               return cached
       
       try:
           # Wrap AWS calls with retry logic
           response = self._retry_aws_call(
               lambda: self.rds_client.describe_db_instances()
           )
           
           results = []
           for db in response['DBInstances']:
               # Process and calculate costs
               results.append({...})
           
           if use_cache:
               self._set_cache(cache_key, results)
           
           return results
       except ClientError as e:
           self.handle_client_error(e, "scan_unused_db_instances")
           return []
   ```

4. **Add unit tests** in `tests/test_rds_scanner.py`:
   ```python
   def test_scan_unused_db_instances(mocker):
       # Mock boto3 client
       # Test caching
       # Test error handling
       pass
   ```

5. **Integrate in `cli.py`:**
   ```python
   from scanners.rds_scanner import RDSScanner
   
   @cli.command()
   def scan():
       rds_scanner = RDSScanner(region=region)
       results['unused_db'] = rds_scanner.scan_unused_db_instances()
   ```

### Code Standards

- **Type hints:** All functions must have type hints
- **Docstrings:** All public methods need docstrings
- **Error handling:** Use `_retry_aws_call()` for AWS API calls
- **Caching:** All scan methods should support `use_cache` parameter
- **Testing:** Minimum 80% code coverage
- **Linting:** Must pass `ruff check .` with no errors

## ü§ù Contributing

Contributions welcome! Here's how to contribute:

1. **Fork the repository**

2. **Create a feature branch:**
   ```bash
   git checkout -b feature/your-scanner-name
   ```

3. **Make your changes:**
   - Follow the code standards above
   - Add tests for new functionality
   - Update documentation

4. **Run tests and linting:**
   ```bash
   pytest tests/ -v
   ruff check .
   mypy scanners/ analyzers/ --ignore-missing-imports
   ```

5. **Commit your changes:**
   ```bash
   git commit -m "Add: New scanner for RDS instances"
   ```

6. **Push and create Pull Request**

### What We're Looking For

- New resource scanners (RDS, Lambda, CloudWatch Logs, etc.)
- Performance improvements
- Documentation improvements
- Bug fixes
- Test coverage improvements

### Code Review Process

1. All PRs require at least one approval
2. All tests must pass
3. Code coverage must not decrease
4. Linting must pass

## üìö What I Learned

This project taught me:
- **boto3** - AWS SDK for Python with pagination patterns
- **click** - Building professional CLI tools
- **Production practices** - Type hints, docstrings, error handling
- **Cost optimization** - Understanding AWS pricing models
- **Testing** - Unit tests with mocks for AWS APIs

## üîÆ Future Enhancements

- [x] Multi-region scanning (scan all regions in parallel)
- [x] Cost Explorer API integration (actual cost data)
- [x] Caching with 5-minute TTL
- [x] Retry logic for transient AWS errors
- [x] GitHub Actions CI/CD pipeline
- [x] CSV export format
- [x] IAM access key scanning
- [x] S3 bucket scanning
- [ ] RDS instance analysis
- [ ] Lambda function analysis
- [ ] CloudWatch Logs analysis
- [ ] Docker containerization
- [ ] Slack/Email notifications
- [ ] Historical cost tracking
- [ ] Web dashboard

## üìù License

MIT License - Free to use and modify

---

**If this tool helped you save money on AWS, consider starring the repo! ‚≠ê**
